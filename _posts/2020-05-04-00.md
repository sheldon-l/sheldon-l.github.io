---
layout: post
title: DevOps 2 - Introduction to DevOps/SRE
published_at: "2020-05-01"
updated_at: "2020-05-01"
author: Taners
tags: [Linux, printer]
---

## History of DevOps and SRE

### The Pre-DevOps Era (Before 2007)

- Releases = thriller movie
- Infrastructure is not flexive
- Continuous Integration was in a very nascent stage: Cruise Control, Hudson
- Monitoring: `Nagios`, didn't have a way to pull out the logs and centrally  manage it.

### Emergence of DevOps

- 2008

  - Use centralized configuration management system `Puppet`, mainly for laptops and desk tops.
  - Use containers for production systems.
  - `Borg`, orchestrator for containers.
  - `cgroup` kernel offered a process resources isolation.
  - Linux Containers (`lxc`), built on top of cgroups and namespaces.
  - Agile Systems Administrator Group.

- 2009:

  - Cloud, such as AWS, including VPCs, the Elastic Block Stores... featured with autoscaling.
  - video "10+ dyploys per day" on youtube, talking about automation and infrustructure as code, improving the collabration between Dev and Ops.
  - #devops was actually coind.
  - `Chef`

### The Era of Chaos (2010~2015)

- 2011, `Hudson`: open source, recreated to `Jenkins` for some lisence reasons.
- 2012, Ansible.
- dotCloud created a web-based collaborative IDE environment based on `lxc`, where you could write code in one window, and executed in another window, and then was brought to be open source, then named `Docker`, and became the fastest moving project of 2013.

- Container Orchestration:
  - 2014, Google who has use containers (`Borg`) for almost 8 years, decided to open source a project named `Kubernets`, show the world how to use `Docker` like google.
  - `Docker` releases its own orchestration engine called `Swarm`
  - Apache `MESOS` system, which was being used since 2009, became very popular. It is a hybrid orchestrator, where you could run a Hadoop job, along with a cron job, along with a Spark job,... And they added the container orchestration feature and framework that they added for that was called `Marathon`.

- Configuration management tools:
  - `SALTSTACK`, a new tool based on python, coexist with `Puppet`, `Chef`, and `Ansible`.

- Continuous Integration:
  -Many choices, `Jenkins` is the boss, and others are `Travis CI`, `Bamboo`, `go`, `CircleCI`

### Maturity years (2016~2018)

- `Kubernetes` has matured as the most preferred container orchestration engine of today, `kubernetes` along with `docker` has become sort of standard for running applications:
  - 2016:
    - Featurse: scaling, presets, windows support
    - Tooling: helm, minikube, kubeadm, kops
    - Pokemon Case Study
  - 2017:
    - Featurse: rbac, storage, apps/v1
    - CRI
    - Doker/Mesos become frendly with k8s
    - AKS/EKS Announced
    - Github moves to k8s
  - 2018:
    - AKS/EKS
    - Digitalocean
    - v1.10/v1.11

- `Ansible` has sort of becom a preferred tool for configuration management system. There have been a lot of changes. In today's world, now that Docker along with K8s has become prominent, the application configuration have complete gone away. So, what you are left is just the configuration of your underlying systems, maybe installing k8s itself, doing network configuration, the system configuration, patching, and compliance tools, and so on. `Ansible` is a great tool to fill the rest of the gaps. Red Hat aquired Ansible in 2015.

- `Jenkins` always been sort of the boss in Continuous Integration, but has not been stagnant.

- Now we are talking about "thousands of deploys a day", also high reliability, availability, scalability, and security.

### Five Pillars Now

- Cloud: AWS, Azure, GCP

- Containers: `Docker` and `k8s`

- IaaC (Infrastructur as a code): `Ansible`, `Terraform`, `Docker compose`, `kubernetes scripts`.

- CI/CD (Continuous Integration / Continuous Delivery): `Jenkins`. Always consider Jenkins at your start point, "Pipeline as a code", `Jenkins` + `Docker`, `Jekins` + `Spinnaker` (a hybrid deployment tool, deploy on multipul clouds and regions)

- Obserbability: It does not mean that you just go and install a bunch of tools, it is also about setting up the culture of observability.
  - monitorint systems: instead of using `Nagios` and `Graphaite`, we now have `Prometheus` which collects multi-dimensional data
  - logs: `ELK` stack (`Elasticsearch`, `Logstash`, `Kibana`)
  - metrics: `Prometheus` is more like a time series database with multiple dimensions that you can store, and `Grafana` is a visualizer for it.
  - traces (especially in distributed systems): `Jaeger`, `Zipkin`

### Future It May Be

- Service Mesh:
  - sits on `Kubernetes`
  - `Istio` and `Linked`
  - Extends Kubernetes through `CRD`
  - Moves away infrastructure concerns to platform.
  - Sample Features: telemetry, intelligent routing, canary, application resilience (timeouts, retries circuit breakers), fault injection.
- Continuous Delivery Fundation (<cd.fundation>)
  - JenkinsX:
    - Automated CI/CD, for Kubernetes workloads.
    - Runs on Kubernetes, integrates with Jenkins, Github, K8s ...
    - Integration with git - feedback to commits, pull requests.
    - Creates automated preview environments for pull requests.
    - Works with `gitops` for promoting code to environments.
  - Tekton:
    - Native kubernetes resources for CI/CD
    - Work with Jenkins, JenkinsX, Scaffold, and Knative, among others.
    - Rolling, blue/green, canary deployment, or `gitops` workflow.
    - Deploy across multiple cloud providers.

## Why Cloud Computing

- Utility Computing Model
- Global Infrastructure
- Scalable Platform
- OPEX vs. CAPEX (Operational Expenses vs. Capital Expenses)
- Dynamic Capacity
- Availability
- Business Continuity
- Managed Services
- Automation

## History of Cloud Computing

- 1961, Jhon McCarthy, "Time sharing model will result in future where computing power will be sold as a utility."
- 1960s, the world was running on **mainframes**.
- Around 60s and 70s, distributed model of computing, **client-server (peer to peer) model** started along with, also the fundation of **grid computing**.
  - Distribution
  - High Performance
  - Cost Effective
  - Scalability
- 1991, **WWW**, use the disparate set of computers across the globe.
- 1999, **virtualization**, VMware
- 1999, based on all above, [Salesforce](salesforce.com), offered web-based applications, kinds like **PaaS** and **Saas**, is the beginning of cloud computing.
- 2006, AWS (`S3`-Storage Services, `EC2`-Elastic Cloud Compute), **Iaas**
- 2008, AWS (`VPC`, `EBS`-Elastic Block Storage, `ELB`-Elastic Block Balancer, `auto-scaling`), Google Cloud Engine
- 2009, Azure
- Now, as Jhon McCarthy said, infrastructure is similar to utility model, like how you buy water, power, gas..., you pay at the end of the month according to your units.

## Type of Cloud Computing

### IaaS

- Want to have a complete control over the kind of infrastructure. AWS, GCP, Azure.

- You would be setting up your infrastructure on cloud, then installing and configuring everything, including `Docker` or `Kubernetes`

### PaaS

- Want to leverage a lot of components which are already there. Som Services of Azure, AWS-EB (Elastic Beantalk), RedHat-OpenShift.

- You not only need to know about `Docker`, and you should have a good working knowledge, operational knowledge about it, but also an orchestration engine which helps you to deploy your container workloads in a production-like environment, where it comes to `Kubernetes`. `Scource` -> `Image` -> Deployed at scale. You don't have a lot of control over the platform

### SaaS

- Any application that you use today, where you don't have to install the software.

## Cloud Deployment Models

### Public Cloud

- Accessible to everyone and anyone, all you need is to create an account with your credit card. AWS, Azure, GCP, DigitalOcean

### Private Cloud

- Inside your own perimeter, your own datacenter. OpenStack help you biuld your own private cloud platform.

### Hybrid Cloud

- Have their own infrastructure locally, and set up the public cloud infrastructure as well, they use virtual private link here to connect to the public cloud and make it seamless for the internel users.

## Major Cloud Services

- One example of a domain-specific service:

### Computer Services

- Be able to create certain virtual machines or cloud servers or droplets or instances ... what ever you call.
- Today a unit of computer can also be a container.

### Databases

- SQL
- NoSQL

### Storage

- Object-based storage: don't attach it to a computer unit, it is something that you store just files or objects and you can connect to that and upload or retrive it using API calls programmatically, or using HTTP URLs and so on.
- Block storage: like provisioning your disks or SSD, attached to your computer

### Network Services

- Virtual private cloud: the ability to define your network configurations, the ability to create a firewall at the network level (Network ALCs), the ability to divide into subnets, the ablility to provide your own IP address and schemes, the abliblity to keep certain areas of infrastructure as private.

### User management Services

- IAM (Identity Access Manage ment)

### Others

- push notifications, analytics, routing, DNS ...
- [AWS Cloudformation](https://aws.amazon.com/tw/cloudformation/) (IaaC)

## Containers

### Why Containers

- Standardization and consistancy

### History of Containers

- 1970s, `chroot` command, afile system - `namespace`.
- 2001~2004, Linux containers: Solaris came with its own `zones`, BSDs with something called `jails`, also called operation system virtualization.
- 2003~2004, Google started migrate their workload to containers, a cluster manager called `Borg`. They contributed to the Linux Kernel called `cgroup` later.
- 2005, Virtuozzo create their open source version of container system OpenVZ.
- 2008, `cgroup` and `namespace`, became core part of the Linux Kernel.
- dotCloud who was founded in 2009, raised some founding, were trying to build a product using `lxc`, an online IDE which can write code in one window and execute on another window.
- 2012, running out of fund, they named the project `docker` and brought it open source.
- 2014, `Borg` -> `kubernetes`
- Apache `MESOS` system, which was being used since 2009, became very popular. It is a hybrid orchestrator, where you could run a Hadoop job, along with a cron job, along with a Spark job,... And they added the container orchestration feature and framework that they added for that was called `Marathon`.
- 2015, `kubernetes` matured and win.

### Under the Hood of Docker

- `cgroup`
- `namespace`
- system-level virtualization, Windows containers on Windows, Linux Containers on Linux, and so on.
- layers

### Why Kubernetes

- scheduling
- network
- reliability, availability, scalability, security

## Infrastructure as a Code

### Why IaaC

- Scale
- Consistency
- Centralized management system
- Less amount of time
- Reproducible infrastructure
- Templates - Code as data

### 5 Categories of Infrastructure as a Code Tools

- VM provisioning: Vagrant
- Cloud provisioning: Packer, Cloudformation, Terraform (HCL - HashiCorp Configuration Language), Ansible (YAML)
- Configure management system: Used to be a lot, Chef, Puppet, Anisible, Saltstack.... But thanks to Continuous technology, no application configuration to be done by those. And Anisible is good enough to server other configurations.
- Containers: Dockeriles, Docker Compose (YAML), Kubernetes
- CI/CD: Jenkins, Spinnaker

### 5 Fundamental Features of a IaaC Tool

- Declarative syntax: focus on what you want, let the tools handle the "how" part.
- Ability to store it as a code: writ it and store it as a code, use some of the best practices that developers have, such as test-driven development, peer programming, pair programming, automated testing, IDEs ...
- Idempotence: have the intellegence to make sure the current state matches the desired state.
- Self documented code
- Templates

## CI/CD

### Why CI/CD

- Reliablility: minimize defects, get feedback

### Workflow and Integration

- Work in team, but share the codebase
- Everyone checks out the code from a common repository
- Maintain a mainline version of the code, typically a master branch.
- Teams create their respective branches of development.
- To support agile practices, work on smaller batches of changes, and integrate often by merging the code to master.

### Desired Tools for CI Tool

- Ability to create jobs to run build, tests, packing etc. by integrating with various tools.
- Connect those jobs to create a sequence of execution piplines.
- Run these piplines in an automated way.
- Ability to trigger these piplines based on external events, e.g. pushing code to a git repo.
- Examples: **Jenkins**, Go, Bamboo, Travis CI, Circle CI.

### CI

- How do we test the code?
  - Pipline similar to assembly line (1915, Henry Ford)
- What all do we test?
  - Unit test
  - Integration test
  - Static analysis (SonarQube)
  - Integration tests
  - Acceptance tests
  - Load tests
  - Compliance tests
- When is the good time to run the test?
  - Since our dev workflow are collaborative, it becomes imperative to test the code whenever we **integrate**
  - [Integration + Biuld + Unit tests + Static checks + Integration tests + Acceptance tests + Load tests + Compliance tests] * continuously

- With CI, we just ensured that the code merged into master is stable, Build -> Tests -> Package

### CD

- Continuous Deployment vs. Continuous Delivery
  - Continuous Deployment: Package -> Deploy to Dev -> Deploy to Stage -> Deploy to Prod
  - Continuous Delivery: Package -> Deploy to Dev -> Deploy to Stage -> Got Permission to Delivery (Release Manager) -> Deploy to Prod
  - Continuous Delivery is better:
    - controlled and safer
    - stress free deployments
    - allow for manual and exploratory testing
    - could accommodate hybrid deployments, e.g. schema updates by hand + auto deploy.
    - allowed for scheduled releases

- Pre requisites (Principles):
  - Agile
  - Biuld automated and quick (Maven for Java, npm for NodeJS, makefiles)
  - Tests pyramid: it is expensive to detect the defects in the later part

  ```bash
              Exploratory Test
            |-|
            Automated UI Test
          |-----|
          Automated API Test
        |---------|
        Automated Service Test
      |--------------|
      Automated Components Test
    |------------------|
    Automated Unit Test
  |----------------------|
  ```

  - Automated Deployments

- Practices:
  - Revision controlled:
    - Application code
    - Build logic (pom.xml, package.json, makefiles)
    - Configurations
    - CI Piplines (Jenkinfiles)
    - Artifact build and packaging logic (Dockerfile)
    - Infrastructure as a code (Ansible)
    - Deployment Logic (kubernetes, deployment files)
  - Development workflow: Github workflow, Git workflow
  - Automated CI Pipelines
  - Automated Deployment Pipelines (`Spinnaker` - adding schema changes, doing canary releases, blue-green deployments)

- Continuous Delivery
  - Setup revision control: Git + Github
  - Define development workflow and code review
  - Setup CI platform
  - Create CI Pipline - Biuld, Test
  - Build and manage artefacts - Packaging Jobs
  - Setup deployment tools and create deployment pipline

### Release Strategy

- Stop services (downtime update);
- Rolling update (zero downtime);
- Blue/green releases: setup a parallel infrustructure, then move links;
- Canary releases: select certain customers direct to beta;
- A/B testing: randomly select beta customers
- Feature flags: already have updated version deployed to servers, but you enable that release on release day by just switching a feature

## Observability

### Why Observability

- Trouble shoot

### What To Observe and How

- Metrics: Prometheus, Grafana
- Logs: Elesticsearch, Kibana
- Traces: Jaeger, then finde the nodes with problem and check the Metrics and Traces.

### SLAs, SLOs, SLIs

- SLAs: contract between the provider and the client, defined as percentage (99% means using 1% leeway to perform maintenance activities)
- SLOs: Servers Level Objective
- SLIs
